{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spayot/miniforge3/envs/tfm0/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading existing datasets from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.97k/3.97k [00:00<00:00, 844kB/s]\n",
      "Downloading metadata: 100%|██████████| 3.28k/3.28k [00:00<00:00, 1.28MB/s]\n",
      "Downloading readme: 100%|██████████| 8.78k/8.78k [00:00<00:00, 5.18MB/s]\n",
      "No config specified, defaulting to: emotion/split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset emotion/split to /Users/spayot/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 592k/592k [00:00<00:00, 1.99MB/s]\n",
      "Downloading data: 100%|██████████| 74.0k/74.0k [00:00<00:00, 603kB/s]\n",
      "Downloading data: 100%|██████████| 74.9k/74.9k [00:00<00:00, 588kB/s]\n",
      "Downloading data files: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 172.16it/s]\n",
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset emotion downloaded and prepared to /Users/spayot/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1138.00it/s]\n"
     ]
    }
   ],
   "source": [
    "emotions = datasets.load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating own datasets\n",
    "## generating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love kyries</td>\n",
       "      <td>basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best running shoes</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleats for forwards</td>\n",
       "      <td>global football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>everyday cool looking snkrs</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new pegs</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text         category\n",
       "0                i love kyries       basketball\n",
       "1           best running shoes          running\n",
       "2          cleats for forwards  global football\n",
       "3  everyday cool looking snkrs        lifestyle\n",
       "4                     new pegs          running"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPATH = \"../data/simple_dataset.csv\"\n",
    "\n",
    "data={\"text\": [\"i love kyries\", \"best running shoes\", \"cleats for forwards\", \"everyday cool looking snkrs\", \"new pegs\"], \n",
    "\"category\": [\"basketball\", \"running\", \"global football\", \"lifestyle\", \"running\"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(FPATH, index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading CSV directly in a dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d1697df20e98b33b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: 157 bytes, generated: 173 bytes, post-processed: Unknown size, total: 330 bytes) to /Users/spayot/.cache/huggingface/datasets/csv/default-d1697df20e98b33b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 737.40it/s]\n",
      "/Users/spayot/miniforge3/envs/tfm0/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:727: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/spayot/.cache/huggingface/datasets/csv/default-d1697df20e98b33b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1169.31it/s]\n"
     ]
    }
   ],
   "source": [
    "ds_pd3 = datasets.load_dataset(\"csv\", \n",
    "    data_files=\"../data/simple_dataset.csv\", \n",
    "    download_mode='force_redownload') # useful if previous version of dataset has already been cached in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'category'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_pd3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a Dataset from a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "label2id =  OrderedDict({\"basketball\": 0, \"running\": 1, \"global football\": 2, \"lifestyle\": 3, \"other\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 15534.46ex/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category', 'label'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pd = datasets.Dataset.from_pandas(df) #, info=\"a toy example of dataset\")\n",
    "\n",
    "\n",
    "def convert_category(example: dict) -> dict[str, int]:\n",
    "    return {\"label\": label2id.get(example[\"category\"])}\n",
    "    \n",
    "ds_pd = ds_pd.map(convert_category)\n",
    "\n",
    "ds_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttext: Value(dtype='string', id=None)\n",
      "\tcategory: Value(dtype='string', id=None)\n",
      "\tlabel: Value(dtype='int64', id=None)\n",
      "\n",
      "\ttext: ['i love kyries', 'best running shoes', 'cleats for forwards', 'everyday cool looking snkrs', 'new pegs']\n",
      "\tcategory: ['basketball', 'running', 'global football', 'lifestyle', 'running']\n",
      "\tlabel: [0, 1, 2, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "def print_dict(d: dict) -> None:\n",
    "    print(*[f\"\\t{k}: {v}\" for k, v in d.items()], sep='\\n')\n",
    "    \n",
    "def print_ds(ds):\n",
    "    print_dict(ds.features)\n",
    "    print()\n",
    "    print_dict(ds[:])\n",
    "\n",
    "print_ds(ds_pd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting right feature types and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.category.map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tlabel: ClassLabel(names=['basketball', 'running', 'global football', 'lifestyle', 'other'], id=None)\n",
      "\ttext: Value(dtype='string', id=None)\n",
      "\tcategory: Value(dtype='string', id=None)\n",
      "\n",
      "\tlabel: [0, 1, 2, 3, 1]\n",
      "\ttext: ['i love kyries', 'best running shoes', 'cleats for forwards', 'everyday cool looking snkrs', 'new pegs']\n",
      "\tcategory: ['basketball', 'running', 'global football', 'lifestyle', 'running']\n"
     ]
    }
   ],
   "source": [
    "features = datasets.Features({\n",
    "    \"label\": datasets.ClassLabel(names=list(label2id.keys())),\n",
    "    \"text\": datasets.Value(dtype=\"string\"),\n",
    "    \"category\": datasets.Value(dtype=\"string\"),\n",
    "    })\n",
    "\n",
    "ds_pd2 = datasets.Dataset.from_pandas(df, features=features)\n",
    "print_ds(ds_pd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "ds_pd2 = ds_pd2.shuffle(seed=42).train_test_split(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Flattening the indices: 100%|██████████| 1/1 [00:00<00:00, 960.45ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Flattening the indices: 100%|██████████| 1/1 [00:00<00:00, 1422.28ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# save to disk in arrow format\n",
    "PATH_TO_DATASET = \"../data/example_dataset/\"\n",
    "ds_pd2.save_to_disk(PATH_TO_DATASET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a local dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spayot/miniforge3/envs/tfm0/lib/python3.9/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'category'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'category'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pd4 = datasets.load_from_disk(\"../data/example_dataset\")\n",
    "ds_pd4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e23854ac13ee28381423b345f08eba333e549fd3a4ba631562d05776809a40e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
